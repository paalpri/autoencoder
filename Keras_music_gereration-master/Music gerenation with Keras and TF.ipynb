{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music gereration firth Keras and TensorFlow backend\n",
    "\n",
    "Plan was simple:\n",
    "1. Read midi file, convert it to matrix of features\n",
    "2. Create simple model with Keras and LSTM to learn the pattern\n",
    "3. Use subsample of initial midi file as a input for model to generate pure art\n",
    "4. Save prediction from model to midi file\n",
    ".\n",
    ".\n",
    ".\n",
    "5. PROFIT\n",
    "\n",
    "<i> For disclamer: I've been using my old Dell Laptop with no GPU support</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile('Samples/Nintendo_-_Pokemon_Fire_Red_Route_1_Piano_Cover_Hard_Version.mid') \n",
    "notes = []\n",
    "velocities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract notes and velocities and then compine it in the one list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in mid:\n",
    "    if not msg.is_meta:\n",
    "        if msg.channel == 0:\n",
    "            if msg.type == 'note_on':\n",
    "                data = msg.bytes()\n",
    "                # append note and velocity from [type, note, velocity]\n",
    "                note = data[1]\n",
    "                velocity = data[2]\n",
    "                notes.append(note)\n",
    "                velocities.append(velocity)\n",
    "combine = [[i,j] for i,j in zip(notes, velocities) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply min-max scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johannes/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "note_min = np.min(notes)\n",
    "note_max = np.max(notes)\n",
    "velocities_min = np.min(velocities)\n",
    "velocities_max = np.max(velocities)\n",
    "\n",
    "for i in combine:\n",
    "    i[0] = 2*(i[0]-((note_min+note_max)/2))/(note_max-note_min)\n",
    "    i[1] = 2*(i[1]-((velocities_min+velocities_max)/2))/(velocities_max-velocities_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare features for training and data subsample for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "n_prev = 30\n",
    "for i in range(len(combine)-n_prev):\n",
    "    x = combine[i:i+n_prev]\n",
    "    y = combine[i+n_prev]\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "# save a seed to do prediction later\n",
    "seed = combine[0:n_prev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Made sequential model with several layers, use LSTM as it time dependent data\n",
    "\n",
    "I also whant to save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(n_prev, 2), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128, input_shape=(n_prev, 2), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(64, input_shape=(n_prev, 2), return_sequences=False))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('linear'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "filepath=\"/Checkpoints_/Checkpoint_model_{epoch:02d}.hdf5\"\n",
    "model_save_callback = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "                                      verbose=1, save_best_only=False, \n",
    "                                      mode='auto', period=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train your model.\n",
    "It might take a while, I was waiting for 1 hour with just 5 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13070/13070 [==============================] - 66s 5ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "13070/13070 [==============================] - 67s 5ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "13070/13070 [==============================] - 65s 5ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "13070/13070 [==============================] - 71s 5ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "13070/13070 [==============================] - 76s 6ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f58806d4748>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X), np.array(Y), 32, 5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "x = seed\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "for i in range(300):\n",
    "    preds = model.predict(x)\n",
    "    x = np.squeeze(x)\n",
    "    x = np.concatenate((x, preds))\n",
    "    x = x[1:]\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = np.squeeze(preds)\n",
    "    prediction.append(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse the min-max scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in prediction:\n",
    "# Undo the preprocessing\n",
    "    pred[0] = int((pred[0]/2)*(note_max-note_min) + (note_min+note_max)/2)\n",
    "    pred[1] = int((pred[1]/2)*(velocities_max-velocities_min) + (velocities_min+velocities_max)/2)\n",
    "    if pred[0] < 24:\n",
    "        pred[0] = 24\n",
    "    elif pred[0] > 102:\n",
    "        pred[0] = 102\n",
    "    if pred[1] < 0:\n",
    "        pred[1] = 0\n",
    "    elif pred[1] > 127:\n",
    "        pred[1] = 127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your result to new midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile()\n",
    "track = MidiTrack()\n",
    "\n",
    "t = 0\n",
    "for note in prediction:\n",
    "    # 147 means note_on\n",
    "    note = np.asarray([147, note[0], note[1]])\n",
    "    bytes = note.astype(int)\n",
    "    msg = Message.from_bytes(bytes[0:3])\n",
    "    t += 1\n",
    "    msg.time = t\n",
    "    track.append(msg)\n",
    "\n",
    "mid.tracks.append(track)\n",
    "mid.save('Generated_song_epoch=5.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just listen to it. The result is surreal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorenv",
   "language": "python",
   "name": "tensorenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
